{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6da1273d-e6cc-4aac-8c22-0d9dc52275ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"650\"\n",
       "            src=\"http://127.0.0.1:8050/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x2d80d71bf20>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import dash\n",
    "from dash import dcc, html\n",
    "from dash.dependencies import Input, Output\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, precision_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "def prepare_data(df):\n",
    "    \"\"\"\n",
    "    Prepare the healthcare data for modeling with proper class encoding.\n",
    "    \"\"\"\n",
    "    df_model = df.copy()\n",
    "    \n",
    "    df_model['Age'] = pd.to_numeric(df_model['Age'].str.extract(r'(\\d+)')[0], errors='coerce')\n",
    "    \n",
    "    # Process dates\n",
    "    df_model['Date Issued'] = pd.to_datetime(df_model['Date Issued'], format='mixed', dayfirst=True)\n",
    "    df_model['Year'] = df_model['Date Issued'].dt.year\n",
    "    df_model['Month'] = df_model['Date Issued'].dt.month\n",
    "    \n",
    "    # Create aspect ratio\n",
    "    df_model['Aspect_Ratio'] = df_model['Width'] / df_model['Height']\n",
    "    \n",
    "    # Select features\n",
    "    features = ['Width', 'Height', 'Aspect_Ratio', 'Age', 'Year', 'Month']\n",
    "    X = df_model[features]\n",
    "    \n",
    "    # Handle missing values\n",
    "    X = X.fillna(X.median())\n",
    "    \n",
    "    # Store original class labels before encoding\n",
    "    unique_classes = df_model['sex'].unique()\n",
    "    \n",
    "    # Properly encode target using LabelEncoder\n",
    "    le = LabelEncoder()\n",
    "    y = le.fit_transform(df_model['sex'])\n",
    "    \n",
    "    # Get unique classes\n",
    "    n_classes = len(unique_classes)\n",
    "    \n",
    "    return X, y, features, n_classes, unique_classes\n",
    "\n",
    "def train_and_evaluate_models(X, y, n_classes):\n",
    "    \"\"\"\n",
    "    Train and evaluate both Decision Tree and XGBoost models.\n",
    "    \"\"\"\n",
    "    # Initialize models\n",
    "    dt = DecisionTreeClassifier(\n",
    "        max_depth=5,\n",
    "        min_samples_split=5,\n",
    "        min_samples_leaf=2,\n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    # Update XGBoost objective for multiclass\n",
    "    xgb = XGBClassifier(\n",
    "        max_depth=4,\n",
    "        learning_rate=0.1,\n",
    "        n_estimators=100,\n",
    "        random_state=42,\n",
    "        objective='multi:softprob',\n",
    "        num_class=n_classes\n",
    "    )\n",
    "    \n",
    "    # Prepare cross-validation\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    \n",
    "    # Store results\n",
    "    results = {\n",
    "        'dt': {'fold_scores': [], 'feature_importance': None},\n",
    "        'xgb': {'fold_scores': [], 'feature_importance': None}\n",
    "    }\n",
    "    \n",
    "    # Perform cross-validation\n",
    "    for fold, (train_idx, val_idx) in enumerate(kf.split(X), 1):\n",
    "        X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "        y_train, y_val = y[train_idx], y[val_idx]\n",
    "        \n",
    "        # Decision Tree\n",
    "        dt.fit(X_train, y_train)\n",
    "        dt_pred = dt.predict(X_val)\n",
    "        dt_score = {\n",
    "            'fold': fold,\n",
    "            'accuracy': accuracy_score(y_val, dt_pred),\n",
    "            'precision_macro': precision_score(y_val, dt_pred, average='macro', zero_division=0),\n",
    "            'precision_weighted': precision_score(y_val, dt_pred, average='weighted', zero_division=0),\n",
    "            'model': 'Decision Tree'\n",
    "        }\n",
    "        results['dt']['fold_scores'].append(dt_score)\n",
    "        \n",
    "        # XGBoost\n",
    "        xgb.fit(X_train, y_train)\n",
    "        xgb_pred = xgb.predict(X_val)\n",
    "        xgb_score = {\n",
    "            'fold': fold,\n",
    "            'accuracy': accuracy_score(y_val, xgb_pred),\n",
    "            'precision_macro': precision_score(y_val, xgb_pred, average='macro', zero_division=0),\n",
    "            'precision_weighted': precision_score(y_val, xgb_pred, average='weighted', zero_division=0),\n",
    "            'model': 'XGBoost'\n",
    "        }\n",
    "        results['xgb']['fold_scores'].append(xgb_score)\n",
    "    \n",
    "    # Get feature importance\n",
    "    results['dt']['feature_importance'] = pd.DataFrame({\n",
    "        'feature': X.columns,\n",
    "        'importance': dt.feature_importances_\n",
    "    })\n",
    "    \n",
    "    results['xgb']['feature_importance'] = pd.DataFrame({\n",
    "        'feature': X.columns,\n",
    "        'importance': xgb.feature_importances_\n",
    "    })\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Initialize Dash app\n",
    "app = dash.Dash(__name__)\n",
    "\n",
    "# Load and prepare data\n",
    "df = pd.read_csv(\"Health_Care_Services.csv\") \n",
    "X, y, features, n_classes, classes_ = prepare_data(df)\n",
    "model_results = train_and_evaluate_models(X, y, n_classes)\n",
    "\n",
    "# Add class information to the dashboard\n",
    "class_info = html.Div([\n",
    "    html.H3('Class Information'),\n",
    "    html.P(f'Number of classes: {n_classes}'),\n",
    "    html.P(f'Original class labels: {\", \".join(str(c) for c in classes_)}')\n",
    "], style={'marginBottom': 20})\n",
    "\n",
    "# Combine results for plotting\n",
    "fold_results = pd.DataFrame(model_results['dt']['fold_scores'] + model_results['xgb']['fold_scores'])\n",
    "\n",
    "# Create the layout\n",
    "app.layout = html.Div([\n",
    "    html.H1('Healthcare Model Analysis Dashboard',\n",
    "            style={'textAlign': 'center', 'color': '#2c3e50', 'marginBottom': 30}),\n",
    "    \n",
    "    class_info,  # Add class information to the dashboard\n",
    "    \n",
    "    # Model Comparison Section\n",
    "    html.Div([\n",
    "        html.H2('Model Performance Comparison',\n",
    "                style={'color': '#2c3e50', 'marginBottom': 20}),\n",
    "        \n",
    "        # Metric selector\n",
    "        html.Div([\n",
    "            html.Label('Select Metrics to Display:'),\n",
    "            dcc.Dropdown(\n",
    "                id='metric-selector',\n",
    "                options=[\n",
    "                    {'label': 'All Metrics', 'value': 'all'},\n",
    "                    {'label': 'Accuracy Only', 'value': 'accuracy'},\n",
    "                    {'label': 'Precision Metrics', 'value': 'precision'}\n",
    "                ],\n",
    "                value='all',\n",
    "                style={'width': '50%'}\n",
    "            )\n",
    "        ], style={'marginBottom': 20}),\n",
    "        \n",
    "        # Performance comparison chart\n",
    "        dcc.Graph(id='model-comparison')\n",
    "    ], style={'marginBottom': 40}),\n",
    "    \n",
    "    # Feature Importance Comparison\n",
    "    html.Div([\n",
    "        html.H2('Feature Importance Comparison',\n",
    "                style={'color': '#2c3e50', 'marginBottom': 20}),\n",
    "        html.Div([\n",
    "            html.Div([\n",
    "                html.H3('Decision Tree Feature Importance',\n",
    "                        style={'textAlign': 'center'}),\n",
    "                dcc.Graph(\n",
    "                    id='dt-feature-importance',\n",
    "                    figure=px.bar(\n",
    "                        model_results['dt']['feature_importance'].sort_values('importance', ascending=True),\n",
    "                        x='importance',\n",
    "                        y='feature',\n",
    "                        orientation='h',\n",
    "                        title='Decision Tree Feature Importance'\n",
    "                    ).update_layout(template='plotly_white')\n",
    "                )\n",
    "            ], style={'width': '48%'}),\n",
    "            html.Div([\n",
    "                html.H3('XGBoost Feature Importance',\n",
    "                        style={'textAlign': 'center'}),\n",
    "                dcc.Graph(\n",
    "                    id='xgb-feature-importance',\n",
    "                    figure=px.bar(\n",
    "                        model_results['xgb']['feature_importance'].sort_values('importance', ascending=True),\n",
    "                        x='importance',\n",
    "                        y='feature',\n",
    "                        orientation='h',\n",
    "                        title='XGBoost Feature Importance'\n",
    "                    ).update_layout(template='plotly_white')\n",
    "                )\n",
    "            ], style={'width': '48%'})\n",
    "        ], style={'display': 'flex', 'justifyContent': 'space-between'}),\n",
    "    ])\n",
    "])\n",
    "\n",
    "@app.callback(\n",
    "    Output('model-comparison', 'figure'),\n",
    "    [Input('metric-selector', 'value')]\n",
    ")\n",
    "def update_model_comparison(selected_metric):\n",
    "    fig = go.Figure()\n",
    "    \n",
    "    for model in ['Decision Tree', 'XGBoost']:\n",
    "        model_data = fold_results[fold_results['model'] == model]\n",
    "        \n",
    "        if selected_metric in ['all', 'accuracy']:\n",
    "            fig.add_trace(go.Scatter(\n",
    "                x=model_data['fold'],\n",
    "                y=model_data['accuracy'],\n",
    "                name=f'{model} - Accuracy',\n",
    "                mode='lines+markers'\n",
    "            ))\n",
    "        \n",
    "        if selected_metric in ['all', 'precision']:\n",
    "            fig.add_trace(go.Scatter(\n",
    "                x=model_data['fold'],\n",
    "                y=model_data['precision_macro'],\n",
    "                name=f'{model} - Precision (Macro)',\n",
    "                mode='lines+markers'\n",
    "            ))\n",
    "            fig.add_trace(go.Scatter(\n",
    "                x=model_data['fold'],\n",
    "                y=model_data['precision_weighted'],\n",
    "                name=f'{model} - Precision (Weighted)',\n",
    "                mode='lines+markers'\n",
    "            ))\n",
    "    \n",
    "    fig.update_layout(\n",
    "        title='Model Performance Comparison Across Folds',\n",
    "        xaxis_title='Fold Number',\n",
    "        yaxis_title='Score',\n",
    "        template='plotly_white',\n",
    "        hovermode='x unified'\n",
    "    )\n",
    "    \n",
    "    return fig\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run_server(debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5742f21b-e7ef-460b-95cb-6066dcb0e0b6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
